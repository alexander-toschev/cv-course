{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "547bdcb6-ae8d-4276-9202-1dfb34159ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mnist in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (0.7)\n",
      "\u001b[33mWARNING: Error parsing requirements for jupyter: [Errno 2] No such file or directory: '/Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages/jupyter-1.0.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mlxtend\n",
      "  Downloading mlxtend-0.22.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (67.6.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (1.1.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (1.23.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from mlxtend) (3.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (4.37.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for jupyter: [Errno 2] No such file or directory: '/Users/alex/miniforge3/envs/mac-ml/lib/python3.8/site-packages/jupyter-1.0.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-mnist\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95ee0b7-3a8b-4d3e-b3b6-82c4dd7d8798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "\n",
    "# Load MNIST data\n",
    "mndata = MNIST('../python-mnist/data')\n",
    "#mndata.gz=True\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "# Preprocess data\n",
    "images = np.array(images) / 255.0\n",
    "labels = np.eye(10)[np.array(labels)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f2fb25-5b7f-403f-a099-d03e0b837eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# number of samples in the data set\n",
    "N_SAMPLES = 1000\n",
    "# ratio between training and test sets\n",
    "TEST_SIZE = 0.1\n",
    "# size of the photo\n",
    "PHOTO_SIZE = 28\n",
    "# number of pixels in the photo\n",
    "PIXEL_NUMBER = PHOTO_SIZE * PHOTO_SIZE\n",
    "# neural network architecture\n",
    "NN_ARCHITECTURE = [\n",
    "    {\"input_dim\": PIXEL_NUMBER, \"output_dim\": 1000, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 1000, \"output_dim\": 1000, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 1000, \"output_dim\": 500, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 500, \"output_dim\": 500, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 500, \"output_dim\": 10, \"activation\": \"softmax\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5ac196-1ee7-49d8-967a-c3c188b0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_dataset():\n",
    "    # The MNIST data set is available at http://yann.lecun.com, let's use curl to download it\n",
    "    if not os.path.exists(\"train-images-idx3-ubyte\"):\n",
    "        !curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "        !curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "        !curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "        !curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "        !gunzip t*-ubyte.gz\n",
    "        \n",
    "    # Let's use loadlocal_mnist available in mlxtend.data to get data in numpy array form.\n",
    "    X1, y1 = loadlocal_mnist(\n",
    "        images_path=\"train-images-idx3-ubyte\", \n",
    "        labels_path=\"train-labels-idx1-ubyte\")\n",
    "\n",
    "    X2, y2 = loadlocal_mnist(\n",
    "        images_path=\"t10k-images-idx3-ubyte\", \n",
    "        labels_path=\"t10k-labels-idx1-ubyte\")\n",
    "    \n",
    "    # We normalize the brightness values for pixels\n",
    "    X1 = X1.reshape(X1.shape[0], -1) / 255\n",
    "    X2 = X2.reshape(X2.shape[0], -1) /255\n",
    "\n",
    "    # Combine downloaded data bundles\n",
    "    X = np.concatenate([X1, X2])\n",
    "    y = np.concatenate([y1, y2])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead3b683-6874-4d4c-b5a2-2730e66abca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    n_values = np.max(y) + 1\n",
    "    return np.eye(n_values)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8155b6b5-6907-4c55-833c-66497136e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(split_percentage):\n",
    "    # Download data\n",
    "    X, y = download_mnist_dataset()\n",
    "    # One hot encode labels\n",
    "    y = one_hot_encoding(y)\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_percentage, random_state=42)\n",
    "    return np.transpose(X_train), np.transpose(X_test), np.transpose(y_train), np.transpose(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f402c1bf-9f24-41f8-b5eb-9acd7b1b6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k  100 9680k    0     0  1659k      0  0:00:05  0:00:05 --:--:-- 1725kk      0  0:00:05  0:00:05 --:--:-- 1720k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881  100 28881    0     0  84446      0 --:--:-- --:--:-- --:--:-- 85194\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k  100 1610k    0     0  1027k      0  0:00:01  0:00:01 --:--:-- 1030k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542  100  4542    0     0  13485      0 --:--:-- --:--:-- --:--:-- 13639\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7ac988-247e-40c9-bcff-20514bf83910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(X, y, idx):\n",
    "    img = X[:, idx].reshape(28,28)\n",
    "    plt.imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "    plt.title('true label: %d' % np.where(y[:, idx] != 0)[0][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad6ca048-0b98-493e-9e62-0946f2ad6045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a67172-80a9-4c65-a4c8-cf9b029df0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    # Column wise softmax\n",
    "    e_Z = np.exp(Z - np.max(Z))\n",
    "    return e_Z / e_Z.sum(axis = 0)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e9778ee-8fba-45ec-9f1e-6514f91caefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2D = np.array([[1, 2, 3, 6],\n",
    "                     [2, 4, 5, 6],\n",
    "                     [3, 8, 7, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "812a516a-cfc4-48b0-90f9-e0c69b388e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09003057, 0.00242826, 0.01587624, 0.33333333],\n",
       "       [0.24472847, 0.01794253, 0.11731043, 0.33333333],\n",
       "       [0.66524096, 0.97962921, 0.86681333, 0.33333333]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(scores2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac316191-af6d-4c6a-999c-1b8bb8161198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:24: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:24: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/49/7n60k7011n11zcdptxxpmvvh0000gn/T/ipykernel_47951/1327592624.py:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if activation is \"relu\":\n",
      "/var/folders/49/7n60k7011n11zcdptxxpmvvh0000gn/T/ipykernel_47951/1327592624.py:24: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif activation is \"sigmoid\":\n",
      "/var/folders/49/7n60k7011n11zcdptxxpmvvh0000gn/T/ipykernel_47951/1327592624.py:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif activation is \"softmax\":\n"
     ]
    }
   ],
   "source": [
    "def init_layers(nn_architecture, seed = 99):\n",
    "    np.random.seed(seed)\n",
    "    number_of_layers = len(nn_architecture)\n",
    "    params_values = {}\n",
    "    \n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        \n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "        \n",
    "        params_values['W' + str(layer_idx)] = np.random.randn(\n",
    "            layer_output_size, layer_input_size) * 0.1\n",
    "        params_values['b' + str(layer_idx)] = np.random.randn(\n",
    "            layer_output_size, 1) * 0.1\n",
    "        \n",
    "    return params_values\n",
    "\n",
    "def single_layer_forward_propagation(A_prev, W_curr, b_curr, activation=\"relu\"):\n",
    "    Z_curr = np.dot(W_curr, A_prev) + b_curr\n",
    "    \n",
    "    if activation is \"relu\":\n",
    "        activation_func = relu\n",
    "    elif activation is \"sigmoid\":\n",
    "        activation_func = sigmoid\n",
    "    elif activation is \"softmax\":\n",
    "        activation_func = softmax\n",
    "    else:\n",
    "        raise Exception('Non-supported activation function')\n",
    "        \n",
    "    return activation_func(Z_curr), Z_curr\n",
    "\n",
    "def full_forward_propagation(X, params_values, nn_architecture):\n",
    "    memory = {}\n",
    "    A_curr = X\n",
    "    \n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        A_prev = A_curr\n",
    "        \n",
    "        activ_function_curr = layer[\"activation\"]\n",
    "        W_curr = params_values[\"W\" + str(layer_idx)]\n",
    "        b_curr = params_values[\"b\" + str(layer_idx)]\n",
    "        A_curr, Z_curr = single_layer_forward_propagation(A_prev, W_curr, b_curr, activ_function_curr)\n",
    "        \n",
    "        memory[\"A\" + str(idx)] = A_prev\n",
    "        memory[\"Z\" + str(layer_idx)] = Z_curr\n",
    "       \n",
    "    return A_curr, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f892a048-b26f-4dca-a742-719d7d9cf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_cross_entropy_loss(Y_hat, Y):\n",
    "    m = Y_hat.shape[1]\n",
    "    loss = - np.sum(Y * np.log(Y_hat)) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b808388-461e-499a-8b21-ea2c38118d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_accuracy(Y_hat, Y):\n",
    "    n_values = Y_hat.shape[0]\n",
    "    values = Y_hat.argmax(axis=0)\n",
    "    Y_hat_one_hot = np.eye(n_values)[values].T\n",
    "    return (Y_hat_one_hot == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a60a29d8-3b39-433f-816c-9f382fca20f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:4: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/49/7n60k7011n11zcdptxxpmvvh0000gn/T/ipykernel_47951/2740823992.py:4: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if activation is \"relu\":\n",
      "/var/folders/49/7n60k7011n11zcdptxxpmvvh0000gn/T/ipykernel_47951/2740823992.py:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif activation is \"sigmoid\":\n",
      "/var/folders/49/7n60k7011n11zcdptxxpmvvh0000gn/T/ipykernel_47951/2740823992.py:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif activation is \"softmax\":\n"
     ]
    }
   ],
   "source": [
    "def single_layer_backward_propagation(dA_curr, W_curr, b_curr, Z_curr, A_prev, activation=\"relu\"):\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    if activation is \"relu\":\n",
    "        backward_activation_func = relu_backward\n",
    "    elif activation is \"sigmoid\":\n",
    "        backward_activation_func = sigmoid_backward\n",
    "    elif activation is \"softmax\":\n",
    "        # TEST OF COURSERA SOLUTION\n",
    "        backward_activation_func = lambda dA_curr, Z_curr: dA_curr\n",
    "    else:\n",
    "        raise Exception('Non-supported activation function')\n",
    "    \n",
    "    dZ_curr = backward_activation_func(dA_curr, Z_curr)\n",
    "    dW_curr = np.dot(dZ_curr, A_prev.T) / m\n",
    "    db_curr = np.sum(dZ_curr, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(W_curr.T, dZ_curr)\n",
    "\n",
    "    return dA_prev, dW_curr, db_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0511358d-8bf9-41d0-a1a7-cc9284f9e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backward_propagation(Y_hat, Y, memory, params_values, nn_architecture, eps = 0.000000000001):\n",
    "    grads_values = {}\n",
    "    m = Y.shape[1]\n",
    "    Y = Y.reshape(Y_hat.shape)\n",
    "    \n",
    "#     dA_prev = - (np.divide(Y, Y_hat + eps) - np.divide(1 - Y, 1 - Y_hat + eps))\n",
    "    # TEST OF COURSERA SOLUTION\n",
    "    dA_prev = Y_hat - Y\n",
    "    \n",
    "    for layer_idx_prev, layer in reversed(list(enumerate(nn_architecture))):\n",
    "        layer_idx_curr = layer_idx_prev + 1\n",
    "        activ_function_curr = layer[\"activation\"]\n",
    "        \n",
    "        dA_curr = dA_prev\n",
    "        \n",
    "        A_prev = memory[\"A\" + str(layer_idx_prev)]\n",
    "        Z_curr = memory[\"Z\" + str(layer_idx_curr)]\n",
    "        \n",
    "        W_curr = params_values[\"W\" + str(layer_idx_curr)]\n",
    "        b_curr = params_values[\"b\" + str(layer_idx_curr)]\n",
    "        \n",
    "        dA_prev, dW_curr, db_curr = single_layer_backward_propagation(\n",
    "            dA_curr, W_curr, b_curr, Z_curr, A_prev, activ_function_curr)\n",
    "        \n",
    "        grads_values[\"dW\" + str(layer_idx_curr)] = dW_curr\n",
    "        grads_values[\"db\" + str(layer_idx_curr)] = db_curr\n",
    "    \n",
    "    return grads_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f998253b-ac45-4f7c-a9e8-c7e509eda73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params_values, grads_values, nn_architecture, learning_rate):\n",
    "\n",
    "    for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "        params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "        params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cec5b078-555c-4557-ad8a-6b2b5a111351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, nn_architecture, epochs, learning_rate, verbose=False, callback=None):\n",
    "    params_values = init_layers(nn_architecture, 2)\n",
    "    cost_history = []\n",
    "    accuracy_history = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        Y_hat, cashe = full_forward_propagation(X, params_values, nn_architecture)\n",
    "        \n",
    "#         print(Y_hat.shape)\n",
    "#         print(Y.shape)\n",
    "        \n",
    "        cost = multi_class_cross_entropy_loss(Y_hat, Y)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "#         print(cost)\n",
    "        \n",
    "        accuracy = multi_class_accuracy(Y_hat, Y)\n",
    "        accuracy_history.append(accuracy)\n",
    "        \n",
    "#         print(accuracy)\n",
    "        \n",
    "        grads_values = full_backward_propagation(Y_hat, Y, cashe, params_values, nn_architecture)\n",
    "        params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "        \n",
    "        if(i % 5 == 0):\n",
    "            if(verbose):\n",
    "                print(\"Iteration: {:05} - cost: {:.5f} - accuracy: {:.5f}\".format(i, cost, accuracy))\n",
    "            if(callback is not None):\n",
    "                callback(i, params_values)\n",
    "            \n",
    "    return params_values, cost_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb595ad4-481c-44f7-b55c-4260ccfc8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 10000\n",
    "X_train = X_train[:,:SUBSET_SIZE]\n",
    "y_train = y_train[:,:SUBSET_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50f00263-f1a6-4528-b73a-ced3738a6c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00000 - cost: 18.05769 - accuracy: 0.09350\n",
      "Iteration: 00005 - cost: 6.55857 - accuracy: 0.34620\n",
      "Iteration: 00010 - cost: 1.29068 - accuracy: 0.67030\n",
      "Iteration: 00015 - cost: 1.01207 - accuracy: 0.73030\n",
      "Iteration: 00020 - cost: 0.85441 - accuracy: 0.76560\n",
      "Iteration: 00025 - cost: 0.75597 - accuracy: 0.78840\n",
      "Iteration: 00030 - cost: 0.68273 - accuracy: 0.80950\n",
      "Iteration: 00035 - cost: 0.62498 - accuracy: 0.82370\n",
      "Iteration: 00040 - cost: 0.57798 - accuracy: 0.83580\n",
      "Iteration: 00045 - cost: 0.53846 - accuracy: 0.84670\n",
      "Iteration: 00050 - cost: 0.50445 - accuracy: 0.85660\n",
      "Iteration: 00055 - cost: 0.47479 - accuracy: 0.86430\n",
      "Iteration: 00060 - cost: 0.44866 - accuracy: 0.87120\n",
      "Iteration: 00065 - cost: 0.42536 - accuracy: 0.87710\n",
      "Iteration: 00070 - cost: 0.40445 - accuracy: 0.88430\n",
      "Iteration: 00075 - cost: 0.38556 - accuracy: 0.88860\n",
      "Iteration: 00080 - cost: 0.36836 - accuracy: 0.89520\n",
      "Iteration: 00085 - cost: 0.35262 - accuracy: 0.89900\n",
      "Iteration: 00090 - cost: 0.33812 - accuracy: 0.90310\n",
      "Iteration: 00095 - cost: 0.32469 - accuracy: 0.90650\n"
     ]
    }
   ],
   "source": [
    "params_values, cost_history, accuracy_history = train(X_train, y_train, NN_ARCHITECTURE, 100, 0.01, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf3c8a90-2b82-46f3-b51e-d009c09490cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602857142857143\n"
     ]
    }
   ],
   "source": [
    "y_test_hat, _ = full_forward_propagation(X_test, params_values, NN_ARCHITECTURE)\n",
    "accuracy = multi_class_accuracy(y_test_hat, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadca41c-55b9-47be-aab9-e79c7a5f936c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
