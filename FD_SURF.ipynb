{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexander-toschev/cv-course/blob/main/FD_SURF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-68VdgCBPCO2"
   },
   "source": [
    "In last chapter, we saw SIFT for keypoint detection and description. But it was comparatively slow and people needed more speeded-up version. In 2006, three people, Bay, H., Tuytelaars, T. and Van Gool, L, published another paper, “SURF: Speeded Up Robust Features” which introduced a new algorithm called SURF. As name suggests, it is a speeded-up version of SIFT.\n",
    "\n",
    "In SIFT, Lowe approximated Laplacian of Gaussian with Difference of Gaussian for finding scale-space. SURF goes a little further and approximates LoG with Box Filter. Below image shows a demonstration of such an approximation. One big advantage of this approximation is that, convolution with box filter can be easily calculated with the help of integral images. And it can be done in parallel for different scales. Also the SURF rely on determinant of Hessian matrix for both scale and location.\n",
    "\n",
    "![image](https://github.com/alexander-toschev/cv-course/raw/main/data/surf_boxfilter.jpg)\n",
    "\n",
    "For orientation assignment, SURF uses wavelet responses in horizontal and vertical direction for a neighbourhood of size 6s. Adequate guassian weights are also applied to it. Then they are plotted in a space as given in below image. The dominant orientation is estimated by calculating the sum of all responses within a sliding orientation window of angle 60 degrees. Interesting thing is that, wavelet response can be found out using integral images very easily at any scale. For many applications, rotation invariance is not required, so no need of finding this orientation, which speeds up the process. SURF provides such a functionality called Upright-SURF or U-SURF. It improves speed and is robust upto \\pm 15^{\\circ}. OpenCV supports both, depending upon the flag, upright. If it is 0, orientation is calculated. If it is 1, orientation is not calculated and it is more faster\n",
    "\n",
    "![image](https://github.com/alexander-toschev/cv-course/raw/main/data/surf_orientation.jpg)\n",
    "\n",
    "For feature description, SURF uses Wavelet responses in horizontal and vertical direction (again, use of integral images makes things easier). A neighbourhood of size 20sX20s is taken around the keypoint where s is the size. It is divided into 4x4 subregions. For each subregion, horizontal and vertical wavelet responses are taken and a vector is formed like this,$ v=( \\sum{d_x}, \\sum{d_y}, \\sum{|d_x|}, \\sum{|d_y|})$. \n",
    "\n",
    "This when represented as a vector gives SURF feature descriptor with total 64 dimensions. Lower the dimension, higher the speed of computation and matching, but provide better distinctiveness of features.\n",
    "\n",
    "For more distinctiveness, SURF feature descriptor has an extended 128 dimension version. The sums of d_x and |d_x| are computed separately for d_y < 0 and d_y $\\geq 0$. Similarly, the sums of d_y and |d_y| are split up according to the sign of d_x , thereby doubling the number of features. It doesn’t add much computation complexity. OpenCV supports both by setting the value of flag extended with 0 and 1 for 64-dim and 128-dim respectively (default is 128-dim)\n",
    "\n",
    "Another important improvement is the use of sign of Laplacian (trace of Hessian Matrix) for underlying interest point. It adds no computation cost since it is already computed during detection. The sign of the Laplacian distinguishes bright blobs on dark backgrounds from the reverse situation. In the matching stage, we only compare features if they have the same type of contrast (as shown in image below). This minimal information allows for faster matching, without reducing the descriptor’s performance.\n",
    "\n",
    "In short, SURF adds a lot of features to improve the speed in every step. Analysis shows it is 3 times faster than SIFT while performance is comparable to SIFT. SURF is good at handling images with blurring and rotation, but not good at handling viewpoint change and illumination change.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x521sg4UeRbq"
   },
   "source": [
    "\n",
    "OpenCV provides SURF functionalities just like SIFT. You initiate a SURF object with some optional conditions like 64/128-dim descriptors, Upright/Normal SURF etc. All the details are well explained in docs. Then as we did in SIFT, we can use SURF.detect(), SURF.compute() etc for finding keypoints and descriptors.\n",
    "\n",
    "First we will see a simple demo on how to find SURF keypoints and descriptors and draw it. All examples are shown in Python terminal since it is just same as SIFT only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hG0BNTOJWVNb",
    "outputId": "044b91a1-af75-4648-eae8-f7f01a65b6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-24 18:15:07--  https://w7.pngwing.com/pngs/710/895/png-transparent-chessboard-mathematics-board-game-chess-game-symmetry-black.png\n",
      "Resolving w7.pngwing.com (w7.pngwing.com)... 172.67.214.225, 104.21.16.171, 2606:4700:3031::ac43:d6e1, ...\n",
      "Connecting to w7.pngwing.com (w7.pngwing.com)|172.67.214.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2370 (2.3K) [image/png]\n",
      "Saving to: ‘png-transparent-chessboard-mathematics-board-game-chess-game-symmetry-black.png.7’\n",
      "\n",
      "png-transparent-che 100%[===================>]   2.31K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-10-24 18:15:08 (26.6 MB/s) - ‘png-transparent-chessboard-mathematics-board-game-chess-game-symmetry-black.png.7’ saved [2370/2370]\n",
      "\n",
      "Requirement already satisfied: opencv-contrib-python==3.4.2.17 in /usr/local/lib/python3.7/dist-packages (3.4.2.17)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!wget https://w7.pngwing.com/pngs/710/895/png-transparent-chessboard-mathematics-board-game-chess-game-symmetry-black.png\n",
    "\n",
    "!pip install opencv-contrib-python==3.4.2.17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n5SR7QdMgwm9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Rk_np1nxO1XE",
    "outputId": "25757fab-e5f9-4512-a86c-5dc31fcda4f7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7.0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/runner/miniforge3/conda-bld/libopencv_1675730269761/work/opencv_contrib/modules/xfeatures2d/src/surf.cpp:1028: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'create'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m gray\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m (cv2\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 6\u001b[0m surf \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxfeatures2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSURF_create\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m kp \u001b[38;5;241m=\u001b[39m surf\u001b[38;5;241m.\u001b[39mdetect(gray,\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mdrawKeypoints(gray,kp, img)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/runner/miniforge3/conda-bld/libopencv_1675730269761/work/opencv_contrib/modules/xfeatures2d/src/surf.cpp:1028: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'create'\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [100, 50]\n",
    "filename = 'content/png-transparent-chessboard-mathematics-board-game-chess-game-symmetry-black.png'\n",
    "img = cv2.imread(filename)\n",
    "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "print (cv2.__version__)\n",
    "surf = cv2.xfeatures2d.SURF_create(50000)\n",
    "kp = surf.detect(gray,None)\n",
    "\n",
    "img=cv2.drawKeypoints(gray,kp, img)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgZGmvgOg30P/M7ByZsL+2",
   "include_colab_link": true,
   "name": "FD_SURF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
