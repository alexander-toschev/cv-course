{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexander-toschev/cv-course/blob/main/ImageProcessing_Jupiter.nb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlsOUubJEo1l"
   },
   "source": [
    "# Замена лиц\n",
    "\n",
    "**Цель**\n",
    "\n",
    "Посмотреть алгоритмы замены лиц\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python\\python38\\lib\\site-packages (21.2.4)\n",
      "Requirement already satisfied: matplotlib in c:\\python\\python38\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python\\python38\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python\\python38\\lib\\site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python\\python38\\lib\\site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\python\\python38\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python\\python38\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\python\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: Pillow in c:\\python\\python38\\lib\\site-packages (8.3.1)\n",
      "Requirement already satisfied: image in c:\\python\\python38\\lib\\site-packages (1.5.33)\n",
      "Requirement already satisfied: pillow in c:\\python\\python38\\lib\\site-packages (from image) (8.3.1)\n",
      "Requirement already satisfied: six in c:\\python\\python38\\lib\\site-packages (from image) (1.12.0)\n",
      "Requirement already satisfied: django in c:\\python\\python38\\lib\\site-packages (from image) (3.2.6)\n",
      "Requirement already satisfied: pytz in c:\\python\\python38\\lib\\site-packages (from django->image) (2021.1)\n",
      "Requirement already satisfied: asgiref<4,>=3.3.2 in c:\\python\\python38\\lib\\site-packages (from django->image) (3.4.1)\n",
      "Requirement already satisfied: sqlparse>=0.2.2 in c:\\python\\python38\\lib\\site-packages (from django->image) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install matplotlib\n",
    "!pip install Pillow\n",
    "!pip install image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pil as PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by obtaining corresponding points. First, we can get a lot of points by automatically ( or manually ) by detecting facial feature points. used dlib to detect 68 corresponding points. Next, I added four more points ( one on the right hand side ear, one on the neck, and two on the shoulders ). Finally, I added the corners of the image and half way points between those corners as corresponding points as well. Needless to say, one can add a few more points around the head and neck to get even better results, or remove the manually clicked points to get slightly worse ( but fully automatic ) results.\n",
    "\n",
    "## Delaunay Triangulation\n",
    "From the previous step we have two sets of 80 points — one set per image. We can calculate the average of corresponding points in the two sets and obtain a single set of 80 points. On this set of average points we perform Delaunay Triangulation. The result of Delaunay triangulation is a list of triangles represented by the indices of points in the 80 points array. In this particular case the triangulation produces 149 triangles connecting the 80 points. The triangulation is stored as an array of three columns. The first few rows of the triangulation is shown below.\n",
    "\n",
    "Find location of feature points in morphed image : In the morphed image M, we can find the locations of all 80 points (x_m, y_m) using equation (1).\n",
    "\n",
    "1. Calculate affine transforms : So we have a set of 80 points in image 1, another set of 80 points in image 2 and a third set of 80 points in the morphed image. We also know the triangulation defined over these points. Pick a triangle in image 1 and the corresponding triangle in the morphed image and calculate the affine transform that maps the three corners of the triangle in image 1 to the three corners of the corresponding triangle in the morphed image. In OpenCV, this can be done using getAffineTransform . Calculate an affine transform for every pair of 149 triangles. Finally, repeat the process of image 2 and the morphed image.\n",
    "1. Warp triangles : For each triangle in image 1, use the affine transform calculated in the previous step to transform all pixels inside the triangle to the morphed image. Repeat this for all triangles in image 1 to obtain a warped version of image 1. Similarly, obtain a warped version for image 2. In OpenCV this is achieved by using the function warpAffine. However, warpAffine takes in an image and not a triangle. The trick is to calculate a bounding box for the triangle, warp all pixels inside the bounding box using warpAffine, and then mask the pixels outside the triangle. The triangular mask is created using fillConvexPoly. Be sure to use blendMode BORDER_REFLECT_101 while using warpAffine. 1. It hides the seams better than Secretary Clinton hides her emails.\n",
    "1. Alpha blend warped images : In the previous step we obtained warped version of image 1 and image 2. These two images can be alpha blended using equation (2), and this is your final morphed image. In the code I have provided warping triangles and alpha blending them is combined in a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTq7o9BIjK2L"
   },
   "source": [
    "\n",
    "# Основные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "po2t_JcQigxn",
    "outputId": "818eed20-8772-46f9-878e-d6b3d01f60d9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read points from text file\n",
    "def readPoints(path) :\n",
    "    # Create an array of points.\n",
    "    points = [];\n",
    "    # Read points\n",
    "    with open(path) as file :\n",
    "        for line in file :\n",
    "            x, y = line.split()\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "    return points\n",
    "\n",
    "# Apply affine transform calculated using srcTri and dstTri to src and\n",
    "# output an image of size.\n",
    "def applyAffineTransform(src, srcTri, dstTri, size) :\n",
    "    \n",
    "    # Given a pair of triangles, find the affine transform.\n",
    "    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n",
    "    \n",
    "    # Apply the Affine Transform just found to the src image\n",
    "    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def morphTriangle(img1, img2, img, t1, t2, t, alpha) :\n",
    "\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t]))\n",
    "\n",
    "\n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1Rect = []\n",
    "    t2Rect = []\n",
    "    tRect = []\n",
    "\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        tRect.append(((t[i][0] - r[0]),(t[i][1] - r[1])))\n",
    "        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
    "        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "\n",
    "\n",
    "    # Get mask by filling triangle\n",
    "    mask = np.zeros((r[3], r[2], 3), dtype = np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(tRect), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "    # Apply warpImage to small rectangular patches\n",
    "    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    img2Rect = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]]\n",
    "\n",
    "    size = (r[2], r[3])\n",
    "    warpImage1 = applyAffineTransform(img1Rect, t1Rect, tRect, size)\n",
    "    warpImage2 = applyAffineTransform(img2Rect, t2Rect, tRect, size)\n",
    "\n",
    "    # Alpha blend rectangular patches\n",
    "    imgRect = (1.0 - alpha) * warpImage1 + alpha * warpImage2\n",
    "\n",
    "    # Copy triangular region of the rectangular patch to the output image\n",
    "    img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] * ( 1 - mask ) + imgRect * mask\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SLqbd_IrFLi"
   },
   "source": [
    "## Load images\n",
    "Images stored on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'data/hillary_clinton.jpg'\n",
    "filename2 = 'data/ted_cruz.jpg'\n",
    "alpha = 0.5\n",
    "    \n",
    "# Read images\n",
    "img1 = cv2.imread(filename1);\n",
    "img2 = cv2.imread(filename2);\n",
    "    \n",
    "# Convert Mat to float data type\n",
    "img1 = np.float32(img1)\n",
    "img2 = np.float32(img2)\n",
    "\n",
    "# Read array of corresponding points\n",
    "points1 = readPoints(filename1 + '.txt')\n",
    "points2 = readPoints(filename2 + '.txt')\n",
    "points = [];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JquKFPJtpfWu"
   },
   "source": [
    "# Exersice 1. \n",
    "Plot points over the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morph images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Compute weighted average point coordinates\n",
    "for i in range(0, len(points1)):\n",
    "    x = ( 1 - alpha ) * points1[i][0] + alpha * points2[i][0]\n",
    "    y = ( 1 - alpha ) * points1[i][1] + alpha * points2[i][1]\n",
    "    points.append((x,y))\n",
    "\n",
    "\n",
    "# Allocate space for final output\n",
    "imgMorph = np.zeros(img1.shape, dtype = img1.dtype)\n",
    "\n",
    "# Read triangles from tri.txt\n",
    "with open(\"data/tri.txt\") as file :\n",
    "    for line in file :\n",
    "        x,y,z = line.split()\n",
    "        \n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        z = int(z)\n",
    "            \n",
    "        t1 = [points1[x], points1[y], points1[z]]\n",
    "        t2 = [points2[x], points2[y], points2[z]]\n",
    "        t = [ points[x], points[y], points[z] ]\n",
    "        # Morph one triangle at a time.\n",
    "        morphTriangle(img1, img2, imgMorph, t1, t2, t, alpha)\n",
    "\n",
    "\n",
    "# Display Result\n",
    "#plt.imshow(\"Morphed Face\", np.uint8(imgMorph))\n",
    "cv2.imshow(\"Morphed Face\", np.uint8(imgMorph))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Копия блокнота \"nb_ch06_05.ipynb\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
